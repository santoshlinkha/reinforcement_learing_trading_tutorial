{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5c79a8d",
   "metadata": {},
   "source": [
    "# Hello World for Pytorch\n",
    "\n",
    "The tensors in pytorch are creatd by `torch.tensor([...], dtype = ...)`. The operations of tensors are same as the ones in numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe6d061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0165, 0.0875],\n",
      "        [0.0512, 0.1382],\n",
      "        [0.1086, 0.3146],\n",
      "        [0.0998, 0.0288],\n",
      "        [0.0075, 0.4139]])\n",
      "tensor(1.5872)\n",
      "tensor([[1.5601, 1.8872, 1.8746],\n",
      "        [0.9561, 0.8141, 0.6230],\n",
      "        [0.9546, 0.8443, 0.4169],\n",
      "        [1.3867, 0.9729, 1.1332],\n",
      "        [1.3957, 1.9708, 1.6355]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "########### broadcasting example ###########\n",
    "a = torch.rand(5, 2)\n",
    "b = torch.rand(1, 2)\n",
    "print(b*a)\n",
    "############### dot product ################\n",
    "a = torch.rand(5)\n",
    "b = torch.rand(5)\n",
    "print(torch.dot(a, b))\n",
    "########### matrix multiplication ##########\n",
    "a = torch.rand(5, 4)\n",
    "b = torch.rand(4, 3)\n",
    "print(torch.matmul(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56404a",
   "metadata": {},
   "source": [
    "Differention on pytorch is done using a built in internal engine called `torch.autograd`. The independent variables are set to required grad. In the following example, $y = {\\bf w}^t {\\bf x} + b$. The gradietns at $x$ and $b$ are given by `x.grad` and `b.grad`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6b227fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.]) tensor([0.8710, 0.2257, 0.1938, 0.7747, 0.3650])\n"
     ]
    }
   ],
   "source": [
    "b = torch.rand(1, requires_grad = True)\n",
    "x = torch.rand(5, requires_grad = True)\n",
    "w = torch.rand(5)\n",
    "\n",
    "y = torch.dot(w, x) + b\n",
    "\n",
    "y.backward()\n",
    "\n",
    "print(b.grad, x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa353e",
   "metadata": {},
   "source": [
    "**Exercise 1.** Construct a linear regression using gradient descent. First initialize the parameters $w$ and $b$. Then generate random data for $x$ and $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "994ee88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first create the parameters for linear regression\n",
    "k = 5\n",
    "b = torch.tensor(8, dtype = torch.float)\n",
    "w = torch.rand(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e92876b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the train data\n",
    "x_train = torch.rand(100, k)*100\n",
    "y_train = torch.matmul(x_train, w) + b + torch.rand(100)*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "2c6838e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "def loss(y_1, y_2): return torch.sum((y_1 - y_2)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "3b126288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 \t LOSS : 235794.5\n",
      "Epoch : 100 \t LOSS : 1948.11\n",
      "Epoch : 200 \t LOSS : 546.07\n",
      "Epoch : 300 \t LOSS : 545.22\n",
      "Epoch : 400 \t LOSS : 544.38\n",
      "Epoch : 500 \t LOSS : 543.53\n",
      "Epoch : 600 \t LOSS : 542.69\n",
      "Epoch : 700 \t LOSS : 541.85\n",
      "Epoch : 800 \t LOSS : 541.02\n",
      "Epoch : 900 \t LOSS : 540.18\n",
      "Epoch : 1000 \t LOSS : 539.35\n"
     ]
    }
   ],
   "source": [
    "W = torch.rand(k, 1, requires_grad = True)\n",
    "B = torch.rand(1, requires_grad = True)\n",
    "lr = torch.tensor([0.01], dtype = torch.float)\n",
    "\n",
    "epochs = 1000\n",
    "LOSS = []\n",
    "\n",
    "for i in range(epochs+1):\n",
    "    y_hat = torch.matmul(x_train, W) + B    \n",
    "    \n",
    "    l = loss(torch.reshape(y_train, y_hat.shape), y_hat)\n",
    "    l.backward()\n",
    "    \n",
    "    LOSS.append(l)    \n",
    "    \n",
    "    # normaize the gradients\n",
    "    n_factor = torch.sqrt(torch.sum(W.grad.data**2) + B.grad.data**2)\n",
    "    W_dir = W.grad.data/n_factor\n",
    "    B_dir = B.grad.data/n_factor\n",
    "    \n",
    "    W.data =  W.data - lr*W_dir\n",
    "    B.data = B.data - lr*B_dir\n",
    "    \n",
    "    \n",
    "    if i%int(epochs/10) == 0 : print(\"Epoch :\", i, \"\\t LOSS :\", round(LOSS[-1].data.item(), 2))    \n",
    "    \n",
    "    \n",
    "    W.grad.data.zero_()\n",
    "    B.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4bbdd653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0168, 0.6260, 0.8029, 0.7137, 0.8705]) tensor([0.0010, 0.6104, 0.7901, 0.7014, 0.8607])\n",
      "tensor([6.2963], requires_grad=True) tensor(8.)\n"
     ]
    }
   ],
   "source": [
    "print(torch.reshape(W, w.shape).data, w)\n",
    "print(B, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d435cb13",
   "metadata": {},
   "source": [
    "We can use one layer Neural Network with $10$ units to approximate it as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fe5e281d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 \t LOSS : 50178656.0\n",
      "Epoch : 100 \t LOSS : 1845363.25\n",
      "Epoch : 200 \t LOSS : 1149.38\n",
      "Epoch : 300 \t LOSS : 857.78\n",
      "Epoch : 400 \t LOSS : 855.26\n",
      "Epoch : 500 \t LOSS : 853.42\n",
      "Epoch : 600 \t LOSS : 851.55\n",
      "Epoch : 700 \t LOSS : 849.69\n",
      "Epoch : 800 \t LOSS : 847.83\n",
      "Epoch : 900 \t LOSS : 845.99\n",
      "Epoch : 1000 \t LOSS : 844.14\n"
     ]
    }
   ],
   "source": [
    "W1 = torch.rand(k, 10, requires_grad = True)\n",
    "B1 = torch.rand(1, requires_grad = True)\n",
    "\n",
    "W2 = torch.rand(10, 1, requires_grad = True)\n",
    "B2 = torch.rand(1, requires_grad = True)\n",
    "\n",
    "lr = torch.tensor([0.01], dtype = torch.float)\n",
    "\n",
    "epochs = 1000\n",
    "LOSS = []\n",
    "\n",
    "for i in range(epochs+1):\n",
    "    y_hat = torch.matmul(torch.matmul(x_train, W1) + B1, W2) + B2\n",
    "    \n",
    "    l = loss(torch.reshape(y_train, y_hat.shape), y_hat)\n",
    "    l.backward()\n",
    "    \n",
    "    LOSS.append(l)    \n",
    "    \n",
    "    \n",
    "    n1_factor = torch.sqrt(torch.sum(W1.grad.data**2) + B1.grad.data**2)\n",
    "    W1_dir = W1.grad.data/n1_factor\n",
    "    B1_dir = B1.grad.data/n1_factor\n",
    "    \n",
    "    n2_factor = torch.sqrt(torch.sum(W2.grad.data**2) + B2.grad.data**2)\n",
    "    W2_dir = W2.grad.data/n2_factor\n",
    "    B2_dir = B2.grad.data/n2_factor\n",
    "    \n",
    "    W1.data = W1.data - lr*W1_dir\n",
    "    B1.data = B1.data - lr*B1_dir\n",
    "    \n",
    "    W2.data = W2.data - lr*W2_dir\n",
    "    B2.data = B2.data - lr*B2_dir\n",
    "    \n",
    "    \n",
    "    if i%int(epochs/10) == 0 : print(\"Epoch :\", i, \"\\t LOSS :\", round(LOSS[-1].data.item(), 2))    \n",
    "    \n",
    "    \n",
    "    W1.grad.data.zero_()\n",
    "    B1.grad.data.zero_()\n",
    "    \n",
    "    W2.grad.data.zero_()\n",
    "    B2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7947e55f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
